{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9c27b8",
   "metadata": {},
   "source": [
    "# Flower Image Classification - Data Exploration\n",
    "\n",
    "This notebook explores the flower image dataset and demonstrates basic data preprocessing steps for our image classification project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set up paths\n",
    "# Adjust this if the notebook is moved\n",
    "SRC_DIR = Path(\"../src\")\n",
    "import sys\n",
    "sys.path.append(str(SRC_DIR.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b443efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from data_loader import download_and_prepare_dataset, prepare_dataset_for_training, visualize_data\n",
    "from model import create_cnn_model, create_transfer_learning_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17570c0",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Dataset\n",
    "\n",
    "We'll use the TensorFlow Flowers dataset, which contains images of 5 types of flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the dataset\n",
    "train_ds, val_ds, class_names, num_classes = download_and_prepare_dataset()\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40323ff0",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Images\n",
    "\n",
    "Let's look at some examples from each class to understand our data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e5dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets for visualization\n",
    "raw_train_ds = train_ds  # Keep a reference to the raw dataset\n",
    "train_ds, val_ds = prepare_dataset_for_training(train_ds, val_ds, cache=False)\n",
    "\n",
    "# Create unbatched dataset for visualization\n",
    "unbatched_ds = train_ds.unbatch()\n",
    "\n",
    "# Visualize some examples\n",
    "visualize_data(unbatched_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564248fd",
   "metadata": {},
   "source": [
    "## 3. Analyze Class Distribution\n",
    "\n",
    "Let's check if our dataset is balanced across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count examples per class\n",
    "class_counts = {name: 0 for name in class_names}\n",
    "\n",
    "for _, label in raw_train_ds:\n",
    "    class_counts[class_names[label.numpy()]] += 1\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Class Distribution in Training Dataset')\n",
    "plt.xlabel('Flower Type')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3781b1b",
   "metadata": {},
   "source": [
    "## 4. Examine Image Properties\n",
    "\n",
    "Let's look at the size distribution and other properties of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82509b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image properties\n",
    "image_sizes = []\n",
    "aspect_ratios = []\n",
    "\n",
    "# Sample some images for analysis\n",
    "for image, _ in raw_train_ds.take(100):\n",
    "    height, width, _ = image.shape\n",
    "    image_sizes.append((height, width))\n",
    "    aspect_ratios.append(width / height)\n",
    "\n",
    "# Plot image size distribution\n",
    "heights, widths = zip(*image_sizes)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(widths, heights, alpha=0.5)\n",
    "plt.title('Image Dimensions')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Height (pixels)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(aspect_ratios, bins=20, alpha=0.7)\n",
    "plt.axvline(x=1, color='r', linestyle='--', label='Square')\n",
    "plt.title('Aspect Ratio Distribution')\n",
    "plt.xlabel('Aspect Ratio (width/height)')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average image size: {np.mean(heights):.1f} x {np.mean(widths):.1f} pixels\")\n",
    "print(f\"Average aspect ratio: {np.mean(aspect_ratios):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d24b02",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing Pipeline\n",
    "\n",
    "Examine the data preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single image for demonstration\n",
    "for image, label in raw_train_ds.take(1):\n",
    "    original_image = image.numpy()\n",
    "    class_name = class_names[label.numpy()]\n",
    "    \n",
    "    # Preprocess the image\n",
    "    # Resize\n",
    "    resized_image = tf.image.resize(image, [224, 224]).numpy()\n",
    "    # Normalize\n",
    "    normalized_image = resized_image / 255.0\n",
    "    \n",
    "    # Display the transformations\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.title(f'Original: {class_name}\\n{original_image.shape}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(resized_image.astype('uint8'))\n",
    "    plt.title(f'Resized: 224x224\\n{resized_image.shape}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(normalized_image)\n",
    "    plt.title(f'Normalized: [0, 1]\\n{normalized_image.shape}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04677015",
   "metadata": {},
   "source": [
    "## 6. Model Architecture Preview\n",
    "\n",
    "Let's examine our model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both models\n",
    "basic_model = create_cnn_model(num_classes=num_classes)\n",
    "transfer_model = create_transfer_learning_model(num_classes=num_classes)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"Basic CNN Model:\")\n",
    "basic_model.summary()\n",
    "\n",
    "print(\"\\nTransfer Learning Model:\")\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4cce4",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Loaded and explored the flowers dataset\n",
    "2. Visualized sample images from each class\n",
    "3. Analyzed the class distribution\n",
    "4. Examined image properties and sizes\n",
    "5. Demonstrated the preprocessing pipeline\n",
    "6. Previewed our model architectures\n",
    "\n",
    "Next steps would be to train the models using our `train.py` script and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e708220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That's it for exploration!\n",
    "print(\"Notebook completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
