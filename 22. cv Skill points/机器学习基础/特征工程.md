# 特征工程基础

特征工程是机器学习中至关重要的一环，它直接影响模型性能。好的特征可以让简单的模型表现优秀，而差的特征即使用复杂模型也难以获得好结果。

## 什么是特征工程？

特征工程是将原始数据转换为更能代表潜在问题模式的特征的过程，使机器学习算法能更好地工作。

## 为什么特征工程重要？

- 提高模型性能
- 减少计算复杂度
- 简化模型，提高可解释性
- 减少过拟合风险

## 特征工程的主要技术

### 1. 数据清洗

处理缺失值、异常值和重复数据。

```python
import pandas as pd
import numpy as np

# 加载数据
df = pd.read_csv('data.csv')

# 查看缺失值
print(df.isnull().sum())

# 处理缺失值 - 使用均值填充数值型数据
df['age'].fillna(df['age'].mean(), inplace=True)

# 处理缺失值 - 使用众数填充分类数据
df['category'].fillna(df['category'].mode()[0], inplace=True)

# 删除异常值 (例如: 移除3个标准差以外的值)
mean = df['value'].mean()
std = df['value'].std()
df = df[np.abs(df['value'] - mean) <= 3*std]
```

### 2. 特征缩放

使特征具有相似的量级，对于许多算法很重要。

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# 标准化 (Z-score标准化): 均值为0，标准差为1
scaler = StandardScaler()
df['value_scaled'] = scaler.fit_transform(df[['value']])

# 归一化: 缩放到[0,1]区间
min_max_scaler = MinMaxScaler()
df['value_normalized'] = min_max_scaler.fit_transform(df[['value']])
```

### 3. 特征编码

将分类变量转换为数值形式。

```python
# 独热编码
encoded = pd.get_dummies(df['category'])
df = pd.concat([df, encoded], axis=1)

# 标签编码
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df['category_encoded'] = encoder.fit_transform(df['category'])
```

### 4. 特征转换

改变特征分布或者提取新特征。

```python
# 对数变换 - 处理偏斜分布
df['log_value'] = np.log1p(df['value'])  # log1p = log(1+x)，避免取0的对数

# 多项式特征
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=2)
poly_features = poly.fit_transform(df[['x1', 'x2']])
```

### 5. 特征选择

选择最相关和最重要的特征。

```python
# 基于相关性选择特征
correlation = df.corr()
print(correlation['target'].sort_values(ascending=False))

# 使用SelectKBest选择特征
from sklearn.feature_selection import SelectKBest, f_classif
X = df.drop('target', axis=1)
y = df['target']
selector = SelectKBest(f_classif, k=5)  # 选择5个最佳特征
X_new = selector.fit_transform(X, y)
selected_features = X.columns[selector.get_support()]
```

### 6. 特征聚合

组合多个特征创建新特征。

```python
# 创建交互特征
df['feature_interaction'] = df['feature1'] * df['feature2']

# 分组统计
df['category_mean'] = df.groupby('category')['value'].transform('mean')
```

## 实际案例：预测房价

下面通过一个预测房价的简单例子，演示特征工程的完整流程：

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# 假设我们有一个房价数据集
data = {
    'area': [750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200],
    'bedrooms': [2, 2, 2, 3, 3, 3, 4, 4, 4, 5],
    'age': [10, 15, 5, 12, 8, 5, 7, 10, 2, 20],
    'neighborhood': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],
    'price': [150000, 160000, 170000, 190000, 200000, 210000, 230000, 240000, 250000, 280000]
}

df = pd.DataFrame(data)

# 1. 划分特征和目标变量
X = df.drop('price', axis=1)
y = df['price']

# 2. 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. 定义预处理步骤
# 数值特征处理
numeric_features = ['area', 'bedrooms', 'age']
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# 分类特征处理
categorical_features = ['neighborhood']
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(drop='first'))
])

# 组合所有预处理步骤
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 4. 创建特征工程和模型训练的管道
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestRegressor(random_state=42))
])

# 5. 训练模型
pipeline.fit(X_train, y_train)

# 6. 预测并评估
y_pred = pipeline.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f'均方误差: {mse:.2f}')
print(f'均方根误差: {np.sqrt(mse):.2f}')

# 7. 特征重要性
model = pipeline.named_steps['model']
preprocessor = pipeline.named_steps['preprocessor']
feature_names = (numeric_features + 
                 list(preprocessor.named_transformers_['cat']
                      .named_steps['onehot']
                      .get_feature_names_out(categorical_features)))
feature_importance = model.feature_importances_
for name, importance in zip(feature_names, feature_importance):
    print(f'{name}: {importance:.4f}')
```

## 特征工程的最佳实践

1. **了解业务领域**：领域知识对创建有意义的特征至关重要
2. **探索性数据分析**：在特征工程前充分理解数据
3. **特征工程是迭代过程**：不断尝试新特征，评估它们的效果
4. **减少过拟合**：特征越多，过拟合风险越大，注意使用正则化技术
5. **使用交叉验证**：确保特征在不同数据子集上都有效

## 特征工程工具

- **Scikit-learn**：提供全面的特征工程工具
- **Feature-engine**：专注于特征工程的Python库
- **Featuretools**：自动化特征工程工具
- **Pandas**：数据操作和基础特征工程

特征工程是机器学习中最具创造性的部分，它结合了领域知识、数据理解和算法洞察，是提高模型性能的关键步骤。