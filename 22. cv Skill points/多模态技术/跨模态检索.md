# 跨模态检索基础与实践

## 1. 跨模态检索简介

跨模态检索(Cross-Modal Retrieval)是多模态学习的重要应用，它允许我们使用一种模态的数据(如文本)去检索另一种模态的数据(如图像)，反之亦然。例如：
- 使用文本描述搜索匹配的图片
- 通过图片查找相关的文本描述
- 使用音频查找相关的视频片段

### 1.1 应用场景

跨模态检索在日常生活和工作中的应用非常广泛：
- 图像搜索引擎(通过文字描述找图片)
- 内容推荐系统(基于用户观看的视频推荐相关文章)
- 医疗诊断(通过症状描述匹配相关医学图像)
- 电商平台(通过图片搜索类似商品)
- 多媒体内容管理(自动为图片生成标签或描述)

### 1.2 技术挑战

跨模态检索面临以下主要挑战：
- **模态差异**：不同模态的数据表达方式和特征空间完全不同
- **语义鸿沟**：需要弥合不同模态间的语义差异
- **特征表示**：需要为不同模态的数据找到统一或可比较的表示方式
- **匹配度量**：如何定义跨模态数据之间的相似度
- **效率问题**：大规模数据下的检索效率

## 2. 跨模态检索的基本原理

### 2.1 基本框架

跨模态检索的核心思想是将不同模态的数据映射到一个共享的特征空间，使语义相似的内容在该空间中的距离较近：

1. **特征提取**：从不同模态数据中提取特征
2. **特征映射**：将不同模态的特征映射到共享特征空间
3. **相似度计算**：在共享空间中计算查询与候选项的相似度
4. **排序与检索**：根据相似度对候选项进行排序并返回结果

### 2.2 主要方法

跨模态检索的主要方法可分为几类：

1. **基于共享空间的方法**：
   - 典型代表：CCA(规范相关分析)、Deep CCA
   - 原理：学习将不同模态映射到最大化相关性的共享空间

2. **基于统一语义空间的方法**：
   - 典型代表：VSE(视觉语义嵌入)、CLIP(对比语言-图像预训练)
   - 原理：通过对比学习构建统一的语义空间

3. **基于哈希编码的方法**：
   - 典型代表：跨模态哈希(CMH)
   - 原理：将不同模态数据编码为二进制哈希码，加速检索

4. **生成式方法**：
   - 典型代表：基于GAN的方法
   - 原理：学习不同模态之间的转换关系

## 3. 实现文本-图像跨模态检索系统

下面我们将实现一个简单的文本-图像跨模态检索系统，帮助你理解其基本原理。

### 3.1 基于预训练模型的文本-图像检索

这里我们使用预训练的CLIP模型，它由OpenAI开发，已经在大规模数据上训练过，可以直接用于文本-图像检索：

```python
import torch
import clip
from PIL import Image
import os
import numpy as np
from tqdm import tqdm

class SimpleClipRetrieval:
    """基于CLIP的简单跨模态检索系统"""
    
    def __init__(self, model_name="ViT-B/32"):
        """
        初始化检索系统
        
        参数:
            model_name: CLIP模型名称，可选["ViT-B/32", "ViT-B/16", "ViT-L/14", "RN50", "RN101"]
        """
        # 加载CLIP模型和处理器
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model, self.preprocess = clip.load(model_name, device=self.device)
        print(f"CLIP模型已加载到 {self.device} 设备")
        
        # 存储图像和特征
        self.image_paths = []
        self.image_features = []
        self.is_indexed = False
    
    def index_images(self, image_folder):
        """
        索引文件夹中的所有图像
        
        参数:
            image_folder: 包含图像的文件夹路径
        """
        # 收集所有图像文件
        supported_formats = ['.jpg', '.jpeg', '.png', '.bmp']
        self.image_paths = []
        
        for file in os.listdir(image_folder):
            if any(file.lower().endswith(fmt) for fmt in supported_formats):
                self.image_paths.append(os.path.join(image_folder, file))
        
        print(f"找到 {len(self.image_paths)} 张图像")
        
        # 提取并保存所有图像的特征
        self.image_features = []
        
        with torch.no_grad():
            for img_path in tqdm(self.image_paths, desc="处理图像"):
                try:
                    # 加载和预处理图像
                    image = self.preprocess(Image.open(img_path)).unsqueeze(0).to(self.device)
                    
                    # 提取图像特征
                    image_feature = self.model.encode_image(image)
                    
                    # 归一化特征向量
                    image_feature /= image_feature.norm(dim=-1, keepdim=True)
                    
                    # 保存特征
                    self.image_features.append(image_feature.cpu().numpy())
                    
                except Exception as e:
                    print(f"处理图像 {img_path} 时出错: {e}")
        
        # 将特征列表转换为NumPy数组
        self.image_features = np.vstack(self.image_features)
        self.is_indexed = True
        
        print(f"成功索引 {self.image_features.shape[0]} 张图像")
    
    def search_by_text(self, text_query, top_k=5):
        """
        通过文本查询图像
        
        参数:
            text_query: 文本查询
            top_k: 返回的结果数量
        
        返回:
            包含(图像路径, 相似度分数)的列表
        """
        if not self.is_indexed:
            raise ValueError("请先使用index_images()方法索引图像")
        
        # 对文本进行编码
        with torch.no_grad():
            text = clip.tokenize([text_query]).to(self.device)
            text_feature = self.model.encode_text(text)
            text_feature /= text_feature.norm(dim=-1, keepdim=True)
            text_feature = text_feature.cpu().numpy()
        
        # 计算文本与所有图像的相似度
        similarities = np.dot(text_feature, self.image_features.T)[0]
        
        # 获取相似度最高的图像索引
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # 返回结果
        results = []
        for idx in top_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx]),
                'file_name': os.path.basename(self.image_paths[idx])
            })
        
        return results
    
    def search_by_image(self, image_path, top_k=5):
        """
        通过图像查询相似图像
        
        参数:
            image_path: 查询图像的路径
            top_k: 返回的结果数量
        
        返回:
            包含(图像路径, 相似度分数)的列表
        """
        if not self.is_indexed:
            raise ValueError("请先使用index_images()方法索引图像")
        
        # 加载和处理查询图像
        with torch.no_grad():
            image = self.preprocess(Image.open(image_path)).unsqueeze(0).to(self.device)
            image_feature = self.model.encode_image(image)
            image_feature /= image_feature.norm(dim=-1, keepdim=True)
            image_feature = image_feature.cpu().numpy()
        
        # 计算查询图像与所有图像的相似度
        similarities = np.dot(image_feature, self.image_features.T)[0]
        
        # 获取相似度最高的图像索引（排除自身）
        if image_path in self.image_paths:
            # 如果查询图像在索引中，排除它
            idx_self = self.image_paths.index(image_path)
            similarities[idx_self] = -float('inf')  # 将自身的相似度设为负无穷
        
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # 返回结果
        results = []
        for idx in top_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx]),
                'file_name': os.path.basename(self.image_paths[idx])
            })
        
        return results

# 使用示例
# 初始化检索系统
# retriever = SimpleClipRetrieval()
# 索引图像
# retriever.index_images("./images_folder")
# 通过文本搜索图像
# results = retriever.search_by_text("一只猫坐在沙发上", top_k=5)
# for i, res in enumerate(results, 1):
#     print(f"{i}. {res['file_name']} (相似度: {res['similarity']:.4f})")
# 通过图像搜索相似图像
# similar_images = retriever.search_by_image("./images_folder/cat.jpg", top_k=5)
# for i, res in enumerate(similar_images, 1):
#     print(f"{i}. {res['file_name']} (相似度: {res['similarity']:.4f})")
```

### 3.2 构建简单的自定义跨模态检索模型

下面我们不依赖预训练模型，从头实现一个简单的双塔模型来进行文本-图像检索：

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
import numpy as np
import os
import json
from transformers import BertTokenizer, BertModel

class DualEncoderModel(nn.Module):
    """双塔模型用于文本-图像跨模态检索"""
    
    def __init__(self, embedding_dim=512):
        """
        初始化模型
        
        参数:
            embedding_dim: 共享特征空间的维度
        """
        super(DualEncoderModel, self).__init__()
        
        # 图像编码器 - 使用预训练的ResNet
        resnet = models.resnet50(pretrained=True)
        modules = list(resnet.children())[:-1]  # 移除最后的全连接层
        self.image_encoder = nn.Sequential(*modules)
        self.image_projection = nn.Linear(2048, embedding_dim)  # ResNet50特征维度为2048
        
        # 文本编码器 - 使用BERT
        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
        self.bert_model = BertModel.from_pretrained('bert-base-uncased')
        self.text_projection = nn.Linear(768, embedding_dim)  # BERT特征维度为768
        
    def encode_image(self, image_batch):
        """编码图像为特征向量"""
        with torch.no_grad():  # 冻结图像编码器
            features = self.image_encoder(image_batch)
        features = features.view(features.size(0), -1)  # 展平特征
        features = self.image_projection(features)  # 投影到共享空间
        # 归一化特征
        features = features / features.norm(dim=1, keepdim=True)
        return features
    
    def encode_text(self, text_batch):
        """编码文本为特征向量"""
        # 对文本进行标记化和编码
        encoded_input = self.bert_tokenizer(text_batch, padding=True, truncation=True, 
                                         max_length=128, return_tensors='pt')
        if torch.cuda.is_available():
            encoded_input = {k: v.cuda() for k, v in encoded_input.items()}
        
        with torch.no_grad():  # 冻结BERT模型
            outputs = self.bert_model(**encoded_input)
        
        # 使用[CLS]标记的输出作为文本表示
        text_features = outputs.last_hidden_state[:, 0, :]
        text_features = self.text_projection(text_features)  # 投影到共享空间
        # 归一化特征
        text_features = text_features / text_features.norm(dim=1, keepdim=True)
        return text_features
    
    def forward(self, images, texts):
        """正向传播"""
        image_features = self.encode_image(images)
        text_features = self.encode_text(texts)
        return image_features, text_features

class ImageTextDataset(Dataset):
    """图像-文本配对数据集"""
    
    def __init__(self, annotations_file, img_dir, transform=None):
        """
        初始化数据集
        
        参数:
            annotations_file: 包含图像-文本配对的JSON文件
            img_dir: 图像目录
            transform: 图像转换
        """
        with open(annotations_file, 'r') as f:
            self.annotations = json.load(f)
        
        self.img_dir = img_dir
        self.transform = transform or transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                                 std=[0.229, 0.224, 0.225])
        ])
    
    def __len__(self):
        return len(self.annotations)
    
    def __getitem__(self, idx):
        # 获取图像路径和对应的文本描述
        item = self.annotations[idx]
        img_path = os.path.join(self.img_dir, item['image_file'])
        caption = item['caption']
        
        # 加载和转换图像
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        
        return image, caption, item['image_file']

def train_dual_encoder(train_dataset, val_dataset=None, epochs=10, batch_size=32, 
                      learning_rate=1e-4, temperature=0.07):
    """
    训练双塔模型
    
    参数:
        train_dataset: 训练数据集
        val_dataset: 验证数据集
        epochs: 训练轮数
        batch_size: 批量大小
        learning_rate: 学习率
        temperature: 温度参数控制对比损失
    
    返回:
        训练好的模型
    """
    # 初始化数据加载器
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    if val_dataset:
        val_loader = DataLoader(val_dataset, batch_size=batch_size)
    
    # 初始化模型
    model = DualEncoderModel()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
    # 初始化优化器
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    # 训练循环
    for epoch in range(epochs):
        model.train()
        train_loss = 0.0
        
        for batch_idx, (images, captions, _) in enumerate(train_loader):
            images = images.to(device)
            
            # 清零梯度
            optimizer.zero_grad()
            
            # 正向传播
            image_features, text_features = model(images, captions)
            
            # 计算相似度矩阵
            # [batch_size, batch_size]
            similarity = torch.matmul(image_features, text_features.t()) / temperature
            
            # 对比损失：每个图像对应一个文本，每个文本对应一个图像
            labels = torch.arange(similarity.size(0)).to(device)
            loss_i2t = nn.CrossEntropyLoss()(similarity, labels)
            loss_t2i = nn.CrossEntropyLoss()(similarity.t(), labels)
            loss = (loss_i2t + loss_t2i) / 2
            
            # 反向传播和优化
            loss.backward()
            optimizer.step()
            
            # 累积损失
            train_loss += loss.item()
            
            if (batch_idx + 1) % 10 == 0:
                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}')
        
        avg_train_loss = train_loss / len(train_loader)
        print(f'Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss:.4f}')
        
        # 验证
        if val_dataset:
            model.eval()
            val_loss = 0.0
            with torch.no_grad():
                for images, captions, _ in val_loader:
                    images = images.to(device)
                    image_features, text_features = model(images, captions)
                    
                    # 计算相似度和损失
                    similarity = torch.matmul(image_features, text_features.t()) / temperature
                    labels = torch.arange(similarity.size(0)).to(device)
                    loss_i2t = nn.CrossEntropyLoss()(similarity, labels)
                    loss_t2i = nn.CrossEntropyLoss()(similarity.t(), labels)
                    loss = (loss_i2t + loss_t2i) / 2
                    
                    val_loss += loss.item()
            
            avg_val_loss = val_loss / len(val_loader)
            print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {avg_val_loss:.4f}')
    
    return model

# 使用示例
# 创建数据集(假设有一个包含图像-文本对的JSON文件)
# annotations_file = "image_captions.json"
# img_dir = "./images_folder"
# dataset = ImageTextDataset(annotations_file, img_dir)
# 拆分数据集
# total_size = len(dataset)
# train_size = int(0.8 * total_size)
# val_size = total_size - train_size
# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
# 训练模型
# model = train_dual_encoder(train_dataset, val_dataset, epochs=5)
# 保存模型
# torch.save(model.state_dict(), "dual_encoder_model.pth")
```

### 3.3 完整跨模态检索系统

下面的代码整合了模型训练和检索功能，实现了一个完整的文本-图像跨模态检索系统：

```python
class CrossModalRetrieval:
    """文本-图像跨模态检索系统"""
    
    def __init__(self, model_path=None):
        """
        初始化检索系统
        
        参数:
            model_path: 预训练模型的路径，如果提供，将加载该模型
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # 初始化模型
        self.model = DualEncoderModel()
        
        # 如果提供了模型路径，加载预训练的模型
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
            print(f"已加载预训练模型: {model_path}")
        
        self.model = self.model.to(self.device)
        self.model.eval()  # 设置为评估模式
        
        # 初始化图像处理转换
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
        
        # 存储索引的图像
        self.image_paths = []
        self.image_features = []
        self.is_indexed = False
    
    def index_images(self, image_folder):
        """
        索引文件夹中的所有图像
        
        参数:
            image_folder: 包含图像的文件夹路径
        """
        print(f"开始索引图像文件夹: {image_folder}")
        
        # 收集所有图像文件
        supported_formats = ['.jpg', '.jpeg', '.png', '.bmp']
        self.image_paths = []
        
        for file in os.listdir(image_folder):
            if any(file.lower().endswith(fmt) for fmt in supported_formats):
                self.image_paths.append(os.path.join(image_folder, file))
        
        print(f"找到 {len(self.image_paths)} 张图像")
        
        # 提取并保存所有图像的特征
        self.image_features = []
        
        with torch.no_grad():
            for img_path in tqdm(self.image_paths, desc="处理图像"):
                try:
                    # 加载和预处理图像
                    image = Image.open(img_path).convert('RGB')
                    image = self.transform(image).unsqueeze(0).to(self.device)
                    
                    # 提取图像特征
                    image_feature = self.model.encode_image(image)
                    
                    # 保存特征
                    self.image_features.append(image_feature.cpu().numpy())
                    
                except Exception as e:
                    print(f"处理图像 {img_path} 时出错: {e}")
        
        # 将特征列表转换为NumPy数组
        self.image_features = np.vstack(self.image_features)
        self.is_indexed = True
        
        print(f"成功索引 {self.image_features.shape[0]} 张图像")
    
    def search_by_text(self, text_query, top_k=5):
        """
        通过文本查询图像
        
        参数:
            text_query: 文本查询
            top_k: 返回的结果数量
        
        返回:
            包含(图像路径, 相似度分数)的列表
        """
        if not self.is_indexed:
            raise ValueError("请先使用index_images()方法索引图像")
        
        # 对文本进行编码
        with torch.no_grad():
            text_feature = self.model.encode_text([text_query])
            text_feature = text_feature.cpu().numpy()
        
        # 计算文本与所有图像的相似度
        similarities = np.dot(text_feature, self.image_features.T)[0]
        
        # 获取相似度最高的图像索引
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # 返回结果
        results = []
        for idx in top_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx]),
                'file_name': os.path.basename(self.image_paths[idx])
            })
        
        return results
    
    def search_by_image(self, image_path, top_k=5):
        """
        通过图像查询相似图像
        
        参数:
            image_path: 查询图像的路径
            top_k: 返回的结果数量
        
        返回:
            包含(图像路径, 相似度分数)的列表
        """
        if not self.is_indexed:
            raise ValueError("请先使用index_images()方法索引图像")
        
        # 加载和处理查询图像
        with torch.no_grad():
            image = Image.open(image_path).convert('RGB')
            image = self.transform(image).unsqueeze(0).to(self.device)
            image_feature = self.model.encode_image(image)
            image_feature = image_feature.cpu().numpy()
        
        # 计算查询图像与所有图像的相似度
        similarities = np.dot(image_feature, self.image_features.T)[0]
        
        # 获取相似度最高的图像索引（排除自身）
        if image_path in self.image_paths:
            # 如果查询图像在索引中，排除它
            idx_self = self.image_paths.index(image_path)
            similarities[idx_self] = -float('inf')  # 将自身的相似度设为负无穷
        
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # 返回结果
        results = []
        for idx in top_indices:
            results.append({
                'image_path': self.image_paths[idx],
                'similarity': float(similarities[idx]),
                'file_name': os.path.basename(self.image_paths[idx])
            })
        
        return results
    
    def search_most_relevant_image(self, text_query):
        """找到与文本查询最相关的图像"""
        results = self.search_by_text(text_query, top_k=1)
        if results:
            return results[0]
        return None
    
    def search_most_relevant_texts(self, image_path, text_candidates, top_k=1):
        """
        找到与图像最相关的文本
        
        参数:
            image_path: 图像路径
            text_candidates: 候选文本列表
            top_k: 返回的结果数量
        
        返回:
            包含(文本, 相似度分数)的列表
        """
        # 加载和处理查询图像
        with torch.no_grad():
            image = Image.open(image_path).convert('RGB')
            image = self.transform(image).unsqueeze(0).to(self.device)
            image_feature = self.model.encode_image(image)
            image_feature = image_feature.cpu().numpy()
        
        # 编码所有候选文本
        text_features = []
        with torch.no_grad():
            for text in text_candidates:
                text_feature = self.model.encode_text([text])
                text_features.append(text_feature.cpu().numpy())
        
        text_features = np.vstack(text_features)
        
        # 计算图像与所有文本的相似度
        similarities = np.dot(image_feature, text_features.T)[0]
        
        # 获取相似度最高的文本索引
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        # 返回结果
        results = []
        for idx in top_indices:
            results.append({
                'text': text_candidates[idx],
                'similarity': float(similarities[idx])
            })
        
        return results

# 使用示例
# 初始化检索系统
# retriever = CrossModalRetrieval("dual_encoder_model.pth")
# 索引图像
# retriever.index_images("./images_folder")
# 通过文本搜索图像
# results = retriever.search_by_text("一只猫坐在沙发上", top_k=5)
# for i, res in enumerate(results, 1):
#     print(f"{i}. {res['file_name']} (相似度: {res['similarity']:.4f})")
# 通过图像搜索相似图像
# similar_images = retriever.search_by_image("./images_folder/cat.jpg", top_k=5)
# 找到与图像最相关的文本
# texts = ["一只猫坐在沙发上", "狗在草地上跑步", "一个人在看书", "两只猫在玩耍"]
# relevant_texts = retriever.search_most_relevant_texts("./images_folder/cat.jpg", texts)
# print(f"最相关的文本: {relevant_texts[0]['text']} (相似度: {relevant_texts[0]['similarity']:.4f})")
```

## 4. 简单应用示例

下面是一个简单的示例应用，展示如何实际使用跨模态检索系统：

```python
import gradio as gr
import os
from PIL import Image
import numpy as np

def setup_retrieval_demo(retriever, image_folder="./images"):
    """设置Gradio界面进行演示"""
    
    def text_to_image_search(text_query, top_k=5):
        """文本到图像搜索"""
        try:
            results = retriever.search_by_text(text_query, top_k=int(top_k))
            
            # 准备返回的图像和标题
            image_paths = [res['image_path'] for res in results]
            captions = [f"{os.path.basename(res['image_path'])} (相似度: {res['similarity']:.4f})" 
                      for res in results]
            
            return image_paths, captions
        except Exception as e:
            return [], [f"发生错误: {str(e)}"]
    
    def image_to_image_search(image, top_k=5):
        """图像到图像搜索"""
        try:
            # 保存上传的图像
            temp_path = "temp_query_image.jpg"
            if isinstance(image, np.ndarray):
                Image.fromarray(image).save(temp_path)
            else:
                image.save(temp_path)
            
            # 搜索相似图像
            results = retriever.search_by_image(temp_path, top_k=int(top_k))
            
            # 准备返回的图像和标题
            image_paths = [res['image_path'] for res in results]
            captions = [f"{os.path.basename(res['image_path'])} (相似度: {res['similarity']:.4f})" 
                      for res in results]
            
            # 删除临时文件
            if os.path.exists(temp_path):
                os.remove(temp_path)
            
            return image_paths, captions
        except Exception as e:
            return [], [f"发生错误: {str(e)}"]
    
    # 创建Gradio界面
    with gr.Blocks(title="跨模态检索演示") as demo:
        gr.Markdown("# 跨模态检索系统演示")
        gr.Markdown("这个演示展示了如何使用文本查询图像，或使用图像查询相似图像。")
        
        with gr.Tab("文本到图像检索"):
            with gr.Row():
                with gr.Column():
                    text_input = gr.Textbox(label="输入文本查询", placeholder="例如：一只猫坐在沙发上")
                    top_k_text = gr.Slider(minimum=1, maximum=20, value=5, step=1, label="显示结果数量")
                    text_search_button = gr.Button("搜索")
                
                with gr.Column():
                    gallery_text = gr.Gallery(label="检索结果", show_label=True, columns=3, height=600)
                    result_captions_text = gr.JSON(label="详细结果", visible=False)
        
        with gr.Tab("图像到图像检索"):
            with gr.Row():
                with gr.Column():
                    image_input = gr.Image(label="上传查询图像", type="pil")
                    top_k_image = gr.Slider(minimum=1, maximum=20, value=5, step=1, label="显示结果数量")
                    image_search_button = gr.Button("搜索")
                
                with gr.Column():
                    gallery_image = gr.Gallery(label="检索结果", show_label=True, columns=3, height=600)
                    result_captions_image = gr.JSON(label="详细结果", visible=False)
        
        # 设置按钮点击事件
        text_search_button.click(
            fn=text_to_image_search, 
            inputs=[text_input, top_k_text], 
            outputs=[gallery_text, result_captions_text]
        )
        
        image_search_button.click(
            fn=image_to_image_search, 
            inputs=[image_input, top_k_image], 
            outputs=[gallery_image, result_captions_image]
        )
    
    return demo

# 使用示例
# retriever = SimpleClipRetrieval()  # 或者使用CrossModalRetrieval
# retriever.index_images("./your_image_folder")
# demo = setup_retrieval_demo(retriever)
# demo.launch()
```

## 5. 跨模态检索的评估

跨模态检索系统的评估通常使用以下指标：

1. **Mean Average Precision (MAP)**：评估检索结果的平均精度
2. **Recall@K**：在前K个结果中找到相关项的比例
3. **Normalized Discounted Cumulative Gain (NDCG)**：考虑结果排序的评估指标

下面是一个简单的评估代码：

```python
def evaluate_text_to_image_retrieval(retriever, test_data):
    """
    评估文本到图像检索
    
    参数:
        retriever: 检索系统
        test_data: 包含(text_query, relevant_image_paths)对的测试数据
    
    返回:
        评估指标字典
    """
    recall_at_1 = 0
    recall_at_5 = 0
    recall_at_10 = 0
    mean_rank = 0
    
    for query, relevant_paths in test_data:
        # 进行检索
        results = retriever.search_by_text(query, top_k=100)
        retrieved_paths = [res['image_path'] for res in results]
        
        # 计算指标
        ranks = []
        for rel_path in relevant_paths:
            if rel_path in retrieved_paths:
                rank = retrieved_paths.index(rel_path) + 1
                ranks.append(rank)
        
        # 如果没有找到相关图像，使用最大可能的排名
        if not ranks:
            ranks = [len(retriever.image_paths) + 1]
        
        # 更新指标
        best_rank = min(ranks)
        mean_rank += best_rank
        
        recall_at_1 += 1 if best_rank <= 1 else 0
        recall_at_5 += 1 if best_rank <= 5 else 0
        recall_at_10 += 1 if best_rank <= 10 else 0
    
    # 计算平均值
    num_queries = len(test_data)
    metrics = {
        'Recall@1': recall_at_1 / num_queries,
        'Recall@5': recall_at_5 / num_queries,
        'Recall@10': recall_at_10 / num_queries,
        'Mean Rank': mean_rank / num_queries
    }
    
    return metrics

# 使用示例
# test_data = [
#     ("一只猫坐在沙发上", ["cat_sofa.jpg", "cat_couch.jpg"]),
#     ("海滩上的日落", ["sunset_beach.jpg"]),
#     # 更多测试数据...
# ]
# metrics = evaluate_text_to_image_retrieval(retriever, test_data)
# print("评估指标:")
# for metric, value in metrics.items():
#     print(f"{metric}: {value:.4f}")
```

## 6. 总结

跨模态检索是一项强大的技术，它允许我们在不同类型的数据之间建立语义连接。这篇教程介绍了：

1. **基本原理**：将不同模态的数据映射到共享语义空间
2. **实现方法**：
   - 使用预训练的CLIP模型快速实现
   - 自己训练双塔模型进行自定义检索
3. **应用场景**：从文本搜索图像，从图像搜索相似图像，从图像找到相关文本
4. **评估方法**：使用常见的检索评估指标

跨模态检索在现代信息检索、内容推荐、多媒体分析等领域有着广泛的应用。随着技术的发展，特别是大规模预训练模型的出现，跨模态检索系统的性能和可用性也在不断提高。

要进一步提升跨模态检索的性能，可以考虑：
- 使用更复杂的模型架构
- 结合注意力机制
- 添加更多模态（如音频、视频等）
- 使用更大规模和更多样化的数据进行训练
- 结合领域知识进行特定领域的优化