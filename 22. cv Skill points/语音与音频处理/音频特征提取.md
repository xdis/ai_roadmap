# 音频特征提取

## 1. 什么是音频特征提取

音频特征提取是从原始音频信号中提取有意义的特征参数的过程，这些特征可以用于描述音频的各种属性，如音色、节奏、音高等。特征提取是音频处理、语音识别、音乐分析等任务的基础步骤。

原始音频波形包含大量冗余信息，而提取的特征能够以更加紧凑和有意义的方式表示音频信号，使得后续的处理和分析更加高效。

## 2. 常用音频特征

### 2.1 时域特征

时域特征直接从原始音频波形中提取，不需要进行频域变换。

#### 2.1.1 过零率 (Zero Crossing Rate, ZCR)

过零率是指信号在单位时间内穿过零点的次数，它反映了信号的频率变化。高过零率通常表示高频信号或噪声。

```python
import numpy as np
import librosa

def calculate_zcr(audio, frame_length=2048, hop_length=512):
    """
    计算音频信号的过零率
    
    参数:
        audio: 音频信号数组
        frame_length: 帧长度
        hop_length: 帧移长度
    
    返回:
        过零率数组
    """
    zcr = librosa.feature.zero_crossing_rate(
        audio, 
        frame_length=frame_length, 
        hop_length=hop_length
    )
    return zcr[0]  # 返回一维数组

# 使用示例
# audio, sr = librosa.load('audio_sample.wav', sr=None)
# zcr = calculate_zcr(audio)
# print(f"过零率平均值: {np.mean(zcr)}")
```

#### 2.1.2 能量 (Energy)

音频能量表示信号的强度，可用于区分声音和静音段。

```python
def calculate_energy(audio, frame_length=2048, hop_length=512):
    """
    计算音频信号的能量
    
    参数:
        audio: 音频信号数组
        frame_length: 帧长度
        hop_length: 帧移长度
    
    返回:
        能量数组
    """
    # 计算每帧的能量
    energy = np.array([
        sum(abs(audio[i:i+frame_length]**2)) 
        for i in range(0, len(audio), hop_length)
    ])
    return energy

# 使用示例
# energy = calculate_energy(audio)
# print(f"能量平均值: {np.mean(energy)}")
```

#### 2.1.3 短时能量 (Short-time Energy)

短时能量是分帧计算的能量，可以反映音频信号强度随时间的变化。

```python
def calculate_short_time_energy(audio, frame_length=2048, hop_length=512):
    """
    计算音频信号的短时能量
    
    参数:
        audio: 音频信号数组
        frame_length: 帧长度
        hop_length: 帧移长度
    
    返回:
        短时能量数组
    """
    # 使用librosa的RMS能量函数
    rms = librosa.feature.rms(
        y=audio, 
        frame_length=frame_length, 
        hop_length=hop_length
    )
    return rms[0]  # 返回一维数组

# 使用示例
# ste = calculate_short_time_energy(audio)
# print(f"短时能量平均值: {np.mean(ste)}")
```

### 2.2 频域特征

频域特征需要先将时域信号转换到频域，通常使用傅里叶变换（FFT）。

#### 2.2.1 频谱 (Spectrum)

频谱展示了信号中各个频率成分的振幅，反映了音频的频率组成。

```python
import matplotlib.pyplot as plt

def calculate_spectrum(audio, sr, n_fft=2048):
    """
    计算音频信号的频谱
    
    参数:
        audio: 音频信号数组
        sr: 采样率
        n_fft: FFT窗口大小
    
    返回:
        频率数组和对应的幅度数组
    """
    # 计算FFT
    fft_result = np.fft.fft(audio, n=n_fft)
    # 计算幅度谱
    magnitude = np.abs(fft_result)
    # 计算频率轴
    frequency = np.fft.fftfreq(n_fft, 1/sr)
    
    # 只保留正频率部分
    positive_frequency_indices = np.where(frequency >= 0)
    frequency = frequency[positive_frequency_indices]
    magnitude = magnitude[positive_frequency_indices]
    
    return frequency, magnitude

# 使用示例
# freq, mag = calculate_spectrum(audio, sr)
# plt.figure(figsize=(10, 4))
# plt.plot(freq, mag)
# plt.xlabel('频率 (Hz)')
# plt.ylabel('幅度')
# plt.title('频谱')
# plt.tight_layout()
# plt.show()
```

#### 2.2.2 频谱质心 (Spectral Centroid)

频谱质心表示信号频谱的"重心"位置，它与音色的"亮度"感知相关。

```python
def calculate_spectral_centroid(audio, sr, n_fft=2048, hop_length=512):
    """
    计算音频信号的频谱质心
    
    参数:
        audio: 音频信号数组
        sr: 采样率
        n_fft: FFT窗口大小
        hop_length: 帧移长度
    
    返回:
        频谱质心数组
    """
    # 使用librosa计算频谱质心
    centroid = librosa.feature.spectral_centroid(
        y=audio, 
        sr=sr, 
        n_fft=n_fft, 
        hop_length=hop_length
    )
    return centroid[0]  # 返回一维数组

# 使用示例
# centroid = calculate_spectral_centroid(audio, sr)
# print(f"频谱质心平均值: {np.mean(centroid)} Hz")
```

#### 2.2.3 梅尔频谱 (Mel Spectrogram)

梅尔频谱考虑了人耳对频率的非线性感知，是一种更符合人类听觉特性的表示。

```python
def calculate_mel_spectrogram(audio, sr, n_fft=2048, hop_length=512, n_mels=128):
    """
    计算音频信号的梅尔频谱
    
    参数:
        audio: 音频信号数组
        sr: 采样率
        n_fft: FFT窗口大小
        hop_length: 帧移长度
        n_mels: 梅尔滤波器组数量
    
    返回:
        梅尔频谱数组
    """
    # 计算梅尔频谱
    mel_spec = librosa.feature.melspectrogram(
        y=audio, 
        sr=sr, 
        n_fft=n_fft, 
        hop_length=hop_length, 
        n_mels=n_mels
    )
    # 转换为分贝单位
    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
    return mel_spec_db

# 使用示例
# mel_spec = calculate_mel_spectrogram(audio, sr)
# plt.figure(figsize=(10, 4))
# librosa.display.specshow(mel_spec, x_axis='time', y_axis='mel', sr=sr, hop_length=512)
# plt.colorbar(format='%+2.0f dB')
# plt.title('梅尔频谱')
# plt.tight_layout()
# plt.show()
```

### 2.3 声学特征

声学特征是专门为语音信号设计的，通常用于语音识别和说话人识别。

#### 2.3.1 MFCC (梅尔频率倒谱系数)

MFCC是最常用的语音特征之一，它模拟了人类听觉系统对声音的感知。

```python
def calculate_mfcc(audio, sr, n_mfcc=13, n_fft=2048, hop_length=512):
    """
    计算音频信号的MFCC特征
    
    参数:
        audio: 音频信号数组
        sr: 采样率
        n_mfcc: MFCC系数数量
        n_fft: FFT窗口大小
        hop_length: 帧移长度
    
    返回:
        MFCC系数数组
    """
    # 计算MFCC
    mfcc = librosa.feature.mfcc(
        y=audio, 
        sr=sr, 
        n_mfcc=n_mfcc, 
        n_fft=n_fft, 
        hop_length=hop_length
    )
    return mfcc

# 使用示例
# mfcc = calculate_mfcc(audio, sr)
# plt.figure(figsize=(10, 4))
# librosa.display.specshow(mfcc, x_axis='time', sr=sr, hop_length=512)
# plt.colorbar()
# plt.title('MFCC')
# plt.tight_layout()
# plt.show()
```

#### 2.3.2 色度特征 (Chroma Features)

色度特征将声音的频谱投影到12个音高类别（对应于音乐中的12个半音），常用于音乐分析。

```python
def calculate_chroma(audio, sr, n_fft=2048, hop_length=512, n_chroma=12):
    """
    计算音频信号的色度特征
    
    参数:
        audio: 音频信号数组
        sr: 采样率
        n_fft: FFT窗口大小
        hop_length: 帧移长度
        n_chroma: 色度箱数量
    
    返回:
        色度特征数组
    """
    # 计算色度特征
    chroma = librosa.feature.chroma_stft(
        y=audio, 
        sr=sr, 
        n_fft=n_fft, 
        hop_length=hop_length, 
        n_chroma=n_chroma
    )
    return chroma

# 使用示例
# chroma = calculate_chroma(audio, sr)
# plt.figure(figsize=(10, 4))
# librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', sr=sr, hop_length=512)
# plt.colorbar()
# plt.title('色度特征')
# plt.tight_layout()
# plt.show()
```

## 3. 完整的特征提取示例

下面是一个完整的示例，展示如何从音频文件中提取多种特征：

```python
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt

def extract_audio_features(audio_file, display=True):
    """
    从音频文件中提取多种特征
    
    参数:
        audio_file: 音频文件路径
        display: 是否显示可视化结果
    
    返回:
        包含各种特征的字典
    """
    # 加载音频文件
    audio, sr = librosa.load(audio_file, sr=None)
    
    # 计算各种特征
    features = {}
    
    # 1. 波形
    features['waveform'] = audio
    
    # 2. 过零率
    features['zcr'] = librosa.feature.zero_crossing_rate(audio)[0]
    
    # 3. 短时能量
    features['rms'] = librosa.feature.rms(y=audio)[0]
    
    # 4. 频谱质心
    features['spectral_centroid'] = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
    
    # 5. 梅尔频谱
    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)
    features['mel_spectrogram'] = librosa.power_to_db(mel_spec, ref=np.max)
    
    # 6. MFCC
    features['mfcc'] = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    
    # 7. 色度特征
    features['chroma'] = librosa.feature.chroma_stft(y=audio, sr=sr)
    
    # 可视化展示
    if display:
        plt.figure(figsize=(12, 8))
        
        # 1. 波形
        plt.subplot(3, 2, 1)
        librosa.display.waveshow(audio, sr=sr)
        plt.title('波形')
        
        # 2. 过零率
        plt.subplot(3, 2, 2)
        plt.plot(features['zcr'])
        plt.title('过零率')
        
        # 3. 梅尔频谱
        plt.subplot(3, 2, 3)
        librosa.display.specshow(features['mel_spectrogram'], 
                                x_axis='time', y_axis='mel', sr=sr)
        plt.colorbar(format='%+2.0f dB')
        plt.title('梅尔频谱')
        
        # 4. MFCC
        plt.subplot(3, 2, 4)
        librosa.display.specshow(features['mfcc'], x_axis='time', sr=sr)
        plt.colorbar()
        plt.title('MFCC')
        
        # 5. 色度特征
        plt.subplot(3, 2, 5)
        librosa.display.specshow(features['chroma'], y_axis='chroma', x_axis='time', sr=sr)
        plt.colorbar()
        plt.title('色度特征')
        
        # 6. 频谱质心
        plt.subplot(3, 2, 6)
        plt.plot(features['spectral_centroid'])
        plt.title('频谱质心')
        
        plt.tight_layout()
        plt.show()
    
    return features, sr

# 使用示例
# features, sr = extract_audio_features('audio_sample.wav')
```

## 4. 特征提取在实际应用中的例子

### 4.1 音乐流派分类

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os
import pandas as pd

def extract_features_for_classification(audio_file):
    """提取用于分类的特征"""
    audio, sr = librosa.load(audio_file, sr=None)
    
    # 提取各种特征的统计量
    feature_stats = {}
    
    # 1. 过零率
    zcr = librosa.feature.zero_crossing_rate(audio)[0]
    feature_stats['zcr_mean'] = np.mean(zcr)
    feature_stats['zcr_std'] = np.std(zcr)
    
    # 2. 频谱质心
    centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
    feature_stats['centroid_mean'] = np.mean(centroid)
    feature_stats['centroid_std'] = np.std(centroid)
    
    # 3. MFCC (取前13个系数)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    for i in range(13):
        feature_stats[f'mfcc{i+1}_mean'] = np.mean(mfcc[i])
        feature_stats[f'mfcc{i+1}_std'] = np.std(mfcc[i])
    
    # 4. 色度特征
    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
    feature_stats['chroma_mean'] = np.mean(chroma)
    feature_stats['chroma_std'] = np.std(chroma)
    
    return feature_stats

# 音乐流派分类示例(伪代码)
def classify_music_genre(dataset_path):
    """
    从音频数据集中提取特征并进行流派分类
    
    参数:
        dataset_path: 数据集路径，每个流派一个文件夹
    """
    features = []
    labels = []
    
    # 遍历所有流派文件夹
    for genre in os.listdir(dataset_path):
        genre_path = os.path.join(dataset_path, genre)
        if os.path.isdir(genre_path):
            # 遍历该流派下的所有音频文件
            for file in os.listdir(genre_path):
                if file.endswith('.wav') or file.endswith('.mp3'):
                    file_path = os.path.join(genre_path, file)
                    # 提取特征
                    feature_stats = extract_features_for_classification(file_path)
                    features.append(feature_stats)
                    labels.append(genre)
    
    # 转换为DataFrame
    df = pd.DataFrame(features)
    
    # 划分训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(
        df, labels, test_size=0.2, random_state=42
    )
    
    # 标准化特征
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 训练随机森林分类器
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train_scaled, y_train)
    
    # 评估分类器
    accuracy = clf.score(X_test_scaled, y_test)
    print(f"分类准确率: {accuracy:.4f}")
    
    return clf, scaler

# 使用示例
# classifier, scaler = classify_music_genre('path/to/music_dataset')
```

### 4.2 音频情感分析

```python
def extract_emotion_features(audio_file):
    """提取用于情感分析的特征"""
    audio, sr = librosa.load(audio_file, sr=None)
    
    features = {}
    
    # 1. 音高特征
    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr)
    features['pitch_mean'] = np.mean(pitches[pitches > 0])
    features['pitch_std'] = np.std(pitches[pitches > 0])
    
    # 2. 能量特征
    rms = librosa.feature.rms(y=audio)[0]
    features['energy_mean'] = np.mean(rms)
    features['energy_std'] = np.std(rms)
    features['energy_max'] = np.max(rms)
    
    # 3. 速度特征
    onset_env = librosa.onset.onset_strength(y=audio, sr=sr)
    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)[0]
    features['tempo'] = tempo
    
    # 4. 声音持续时间
    non_silent = librosa.effects.split(audio, top_db=30)
    features['speech_rate'] = len(non_silent) / (len(audio) / sr)
    
    # 5. MFCC特征
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    for i in range(13):
        features[f'mfcc{i+1}_mean'] = np.mean(mfcc[i])
    
    return features

# 情感分析示例(伪代码)
def analyze_emotion(audio_file, model_path='emotion_model.pkl'):
    """
    分析音频的情感
    
    参数:
        audio_file: 音频文件路径
        model_path: 预训练情感分析模型路径
    
    返回:
        预测的情感标签
    """
    # 提取特征
    features = extract_emotion_features(audio_file)
    
    # 将特征转换为DataFrame
    df = pd.DataFrame([features])
    
    # 加载预训练模型和缩放器
    import pickle
    with open(model_path, 'rb') as f:
        model, scaler = pickle.load(f)
    
    # 缩放特征
    df_scaled = scaler.transform(df)
    
    # 预测情感
    emotion = model.predict(df_scaled)[0]
    probabilities = model.predict_proba(df_scaled)[0]
    
    # 获取概率最高的三种情感
    emotions = model.classes_
    top3_indices = np.argsort(probabilities)[-3:][::-1]
    
    for i, idx in enumerate(top3_indices):
        print(f"Top {i+1}: {emotions[idx]} ({probabilities[idx]:.2f})")
    
    return emotion

# 使用示例
# emotion = analyze_emotion('speech_sample.wav')
```

## 5. 实用工具和技巧

### 5.1 音频预处理

在提取特征之前，通常需要对音频进行预处理：

```python
def preprocess_audio(audio_file, target_sr=16000, trim_silence=True, normalize=True):
    """
    音频预处理
    
    参数:
        audio_file: 音频文件路径
        target_sr: 目标采样率
        trim_silence: 是否裁剪静音部分
        normalize: 是否归一化音量
    
    返回:
        处理后的音频数据和采样率
    """
    # 加载音频，同时重采样
    audio, sr = librosa.load(audio_file, sr=target_sr)
    
    # 裁剪静音部分
    if trim_silence:
        audio, _ = librosa.effects.trim(audio, top_db=20)
    
    # 归一化音量
    if normalize:
        audio = librosa.util.normalize(audio)
    
    return audio, sr

# 使用示例
# processed_audio, sr = preprocess_audio('speech_sample.wav')
```

### 5.2 特征保存和加载

在处理大量音频文件时，可以将提取的特征保存起来以提高效率：

```python
import pickle
import json

def save_features(features, filename, format='pickle'):
    """
    保存特征
    
    参数:
        features: 要保存的特征
        filename: 保存的文件名
        format: 保存格式，'pickle'或'json'
    """
    if format == 'pickle':
        with open(filename, 'wb') as f:
            pickle.dump(features, f)
    elif format == 'json':
        # 将numpy数组转换为列表
        json_features = {}
        for key, value in features.items():
            if isinstance(value, np.ndarray):
                json_features[key] = value.tolist()
            else:
                json_features[key] = value
        
        with open(filename, 'w') as f:
            json.dump(json_features, f)
    else:
        raise ValueError("Unsupported format. Use 'pickle' or 'json'.")

def load_features(filename, format='pickle'):
    """
    加载特征
    
    参数:
        filename: 文件名
        format: 文件格式，'pickle'或'json'
    
    返回:
        加载的特征
    """
    if format == 'pickle':
        with open(filename, 'rb') as f:
            features = pickle.load(f)
    elif format == 'json':
        with open(filename, 'r') as f:
            features = json.load(f)
        
        # 将列表转换回numpy数组
        for key, value in features.items():
            if isinstance(value, list):
                features[key] = np.array(value)
    else:
        raise ValueError("Unsupported format. Use 'pickle' or 'json'.")
    
    return features

# 使用示例
# 保存特征
# save_features(features, 'audio_features.pkl')
# 加载特征
# loaded_features = load_features('audio_features.pkl')
```

## 6. 总结

音频特征提取是音频处理和分析的基础步骤，通过提取有意义的特征，可以大大简化后续的机器学习和人工智能任务。

主要的音频特征类型包括：
- 时域特征：过零率、能量、短时能量等
- 频域特征：频谱、频谱质心、梅尔频谱等
- 声学特征：MFCC、色度特征等

这些特征可以用于各种应用，如：
- 语音识别
- 音乐流派分类
- 情感分析
- 说话人识别
- 音频检索

随着深度学习的发展，许多任务不再需要手动设计特征，而是直接从原始数据中学习特征。然而，理解和掌握这些传统特征仍然对于理解音频处理原理和解决特定问题非常重要。