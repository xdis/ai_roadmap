# 特征工程工具介绍

特征工程是机器学习中至关重要的一步，它能够显著提高模型性能。本文介绍几种常用的特征工程工具及其基本用法。

## 1. Scikit-learn 特征工程工具

Scikit-learn 提供了丰富的特征工程工具，包括特征缩放、编码、提取和选择。

### 1.1 特征缩放

```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import numpy as np

# 示例数据
data = np.array([[1, 10], [2, 20], [3, 30], [4, 40]])

# 标准化缩放 (均值为0，标准差为1)
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)
print("标准化后数据:")
print(scaled_data)
# 输出示例:
# [[-1.34164079 -1.34164079]
#  [-0.4472136  -0.4472136 ]
#  [ 0.4472136   0.4472136 ]
#  [ 1.34164079  1.34164079]]

# 归一化缩放 (范围在0-1之间)
min_max_scaler = MinMaxScaler()
normalized_data = min_max_scaler.fit_transform(data)
print("\n归一化后数据:")
print(normalized_data)
# 输出示例:
# [[0.  0. ]
#  [0.33333333 0.33333333]
#  [0.66666667 0.66666667]
#  [1.  1. ]]
```

### 1.2 特征编码

```python
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
import pandas as pd

# 示例数据
data = pd.DataFrame({
    '颜色': ['红', '蓝', '绿', '红', '蓝'],
    '尺寸': ['大', '中', '小', '中', '大']
})

# 标签编码 (将分类变量转换为整数)
label_encoder = LabelEncoder()
data['颜色_编码'] = label_encoder.fit_transform(data['颜色'])
print("标签编码后:")
print(data)
# 输出示例:
#   颜色 尺寸  颜色_编码
# 0  红  大       2
# 1  蓝  中       0
# 2  绿  小       1
# 3  红  中       2
# 4  蓝  大       0

# 独热编码
encoder = OneHotEncoder(sparse=False)
one_hot = encoder.fit_transform(data[['颜色']])
one_hot_df = pd.DataFrame(
    one_hot, 
    columns=[f'颜色_{c}' for c in encoder.categories_[0]]
)
result = pd.concat([data, one_hot_df], axis=1)
print("\n独热编码后:")
print(result)
# 输出示例:
#   颜色 尺寸  颜色_编码  颜色_红  颜色_绿  颜色_蓝
# 0  红  大       2    1.0    0.0    0.0
# 1  蓝  中       0    0.0    0.0    1.0
# 2  绿  小       1    0.0    1.0    0.0
# 3  红  中       2    1.0    0.0    0.0
# 4  蓝  大       0    0.0    0.0    1.0
```

### 1.3 特征选择

```python
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.datasets import load_iris

# 加载示例数据
iris = load_iris()
X, y = iris.data, iris.target

# 选择K个最佳特征
selector = SelectKBest(f_classif, k=2)  # 选择2个最相关特征
X_new = selector.fit_transform(X, y)

print("原始特征数量:", X.shape[1])  # 4
print("选择后特征数量:", X_new.shape[1])  # 2
print("特征得分:", selector.scores_)
print("被选中的特征索引:", selector.get_support())
```

## 2. Feature-engine

Feature-engine 是一个专门用于特征工程的Python库，提供了更丰富的特征处理功能。

```python
# 安装: pip install feature-engine
from feature_engine.outliers import Winsorizer
import pandas as pd
import numpy as np

# 示例数据
data = pd.DataFrame({
    'A': [1, 2, 3, 100, 5],  # 包含一个异常值
    'B': [10, 20, 30, 40, 500]  # 包含一个异常值
})

# 处理异常值 - 将超过95%分位数的值替换为95%分位数值
winsor = Winsorizer(capping_method='quantiles', tail='right', fold=0.05)
cleaned_data = winsor.fit_transform(data)

print("原始数据:")
print(data)
print("\n处理异常后:")
print(cleaned_data)
```

## 3. 使用 Pandas 进行特征工程

Pandas 本身就是一个强大的特征工程工具。

```python
import pandas as pd
import numpy as np

# 示例数据
df = pd.DataFrame({
    '日期': pd.date_range(start='2023-01-01', periods=5),
    '值': [10, 20, np.nan, 40, 50],
    '类别': ['A', 'B', 'A', 'C', 'B']
})

# 1. 缺失值处理
df['值_填充'] = df['值'].fillna(df['值'].mean())

# 2. 日期特征提取
df['年'] = df['日期'].dt.year
df['月'] = df['日期'].dt.month
df['星期'] = df['日期'].dt.day_name()

# 3. 分组统计特征
df['类别_均值'] = df.groupby('类别')['值'].transform('mean')

print(df)
```

## 4. Featuretools - 自动特征工程

Featuretools 是一个自动化特征工程的库，可以自动发现和创建特征。

```python
# 安装: pip install featuretools
import featuretools as ft
import pandas as pd

# 示例数据 - 客户和购买记录
customers = pd.DataFrame({
    "customer_id": [1, 2, 3],
    "age": [25, 30, 35],
    "city": ["北京", "上海", "广州"]
})

purchases = pd.DataFrame({
    "purchase_id": [1, 2, 3, 4, 5],
    "customer_id": [1, 2, 1, 3, 2],
    "amount": [100, 200, 150, 300, 250],
    "date": pd.date_range(start='2023-01-01', periods=5)
})

# 创建实体集
es = ft.EntitySet(id="retail")

# 添加实体
es.add_dataframe(
    dataframe_name="customers",
    dataframe=customers,
    index="customer_id"
)

es.add_dataframe(
    dataframe_name="purchases",
    dataframe=purchases,
    index="purchase_id"
)

# 添加关系
es.add_relationship(
    parent_dataframe_name="customers",
    parent_column_name="customer_id",
    child_dataframe_name="purchases",
    child_column_name="customer_id"
)

# 自动生成特征
features, feature_names = ft.dfs(
    entityset=es,
    target_dataframe_name="customers",
    max_depth=2  # 探索深度
)

print("自动生成的特征:")
print(features.head())
```

## 5. 实际应用示例

结合上述工具进行完整的特征工程流程:

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 加载示例数据集 (假设是房价预测)
# 实际应用中替换为你的数据
np.random.seed(42)
n_samples = 100
data = pd.DataFrame({
    '面积': np.random.randint(50, 200, n_samples),
    '房间数': np.random.randint(1, 5, n_samples),
    '位置': np.random.choice(['市中心', '郊区', '城乡结合部'], n_samples),
    '楼龄': np.random.randint(1, 30, n_samples),
    '是否学区房': np.random.choice([True, False], n_samples),
})
# 添加一些缺失值
data.loc[np.random.choice(n_samples, 10), '楼龄'] = np.nan
# 目标变量
data['价格'] = (
    data['面积'] * 1000 
    + data['房间数'] * 50000 
    - data['楼龄'] * 10000 
    + (data['位置'] == '市中心') * 200000 
    + data['是否学区房'] * 100000 
    + np.random.normal(0, 50000, n_samples)
)

# 分离特征和目标
X = data.drop('价格', axis=1)
y = data['价格']

# 分割训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 特征处理流水线
numeric_features = ['面积', '房间数', '楼龄']
categorical_features = ['位置']
boolean_features = ['是否学区房']

# 数值特征处理流水线
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),  # 缺失值处理
    ('scaler', StandardScaler())  # 标准化
])

# 分类特征处理流水线
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # 缺失值处理
    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # 独热编码
])

# 布尔特征处理流水线
boolean_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent'))  # 缺失值处理
])

# 组合所有特征处理流水线
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features),
        ('bool', boolean_transformer, boolean_features)
    ])

# 完整的处理和建模流水线
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('selector', SelectKBest(f_regression, k=5)),  # 特征选择
    ('model', LinearRegression())  # 模型
])

# 训练模型
pipeline.fit(X_train, y_train)

# 评估模型
y_pred = pipeline.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"均方误差: {mse:.2f}")
print(f"均方根误差: {np.sqrt(mse):.2f}")

# 特征重要性分析
# 获取已处理的特征名称
feature_names = []
for name, transformer, features in preprocessor.transformers_:
    if name == 'cat':
        # 获取独热编码生成的特征名称
        encoder = transformer.named_steps['onehot']
        encoded_features = list(encoder.get_feature_names_out(features))
        feature_names.extend(encoded_features)
    else:
        feature_names.extend(features)

# 特征选择器获取最佳特征索引
selected_indices = pipeline.named_steps['selector'].get_support()
selected_features = [feature_names[i] for i in range(len(feature_names)) if selected_indices[i]]

# 如果使用线性回归，可获取系数
if hasattr(pipeline.named_steps['model'], 'coef_'):
    coefficients = pipeline.named_steps['model'].coef_
    feature_importance = dict(zip(selected_features, coefficients))
    print("\n特征重要性:")
    for feature, importance in sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True):
        print(f"{feature}: {importance:.2f}")
```

## 总结

特征工程工具能大幅提高数据处理效率和模型性能:

- **Scikit-learn**: 提供了全面的特征工程工具，包括缩放、编码和选择
- **Feature-engine**: 专门的特征工程库，提供更专业的特征处理功能
- **Pandas**: 强大的数据处理能力，适合基础特征创建和转换
- **Featuretools**: 自动化特征工程，适合复杂关系数据
- **Pipeline**: 构建端到端的特征处理流程，确保一致性

选择合适的特征工程工具取决于数据特点、问题类型和个人偏好。实践中通常需要结合多种工具以获得最佳结果。